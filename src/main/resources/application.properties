spring.application.name=Kafka_Consumer_Message

# Kafka server address
spring.kafka.bootstrap-servers=localhost:9092

# Consumer group ID (identifies the consumer group that this consumer belongs to)
spring.kafka.consumer.group-id=my-group

# Automatically create the topic if it doesn't exist (optional)
spring.kafka.admin.auto-create-topics=true

# Deserializer for incoming messages (value and key should match your producer's format)
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=com.nt.Entity
#spring.kafka.consumer.properties.spring.json.trusted.packages=*

# Enable auto commit of offsets so that the Kafka server knows which messages have been consumed
spring.kafka.consumer.enable-auto-commit=true

# Commit the offset every 1000 milliseconds (adjustable)
spring.kafka.consumer.auto-commit-interval=1000

# Start consuming messages from the latest one (optional, you can also choose earliest to consume from the start)
spring.kafka.consumer.auto-offset-reset=latest

kafka.topic=hello_topic

spring.datasource.url=jdbc:mysql://localhost/spring boot?createDatabaseIfNotExist=true&autoReconnect=true&useSSL=false
spring.datasource.username=root
spring.datasource.password=root
spring.datasource.platform=mysql
spring.datasource.initialization-mode=always
## Hibernate Properties
# The SQL dialect makes Hibernate generate better SQL for the chosen database
# spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5Dialect
# Hibernate ddl auto (create, create-drop, validate, update)
spring.jpa.hibernate.ddl-auto = update
